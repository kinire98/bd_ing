{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169b1dba-2965-4f86-9d14-83592937e1e1",
   "metadata": {},
   "source": [
    "# BIG DATA APLICADO - Examen 1ª Evaluación\n",
    "\n",
    "**Instrucciones generales**\n",
    "\n",
    "1.\tTodas las sentencias deben ejecutarse desde la línea de comandos en las celdas que hay después del enunciado. No debes realizar ninguna tarea desde fuera de Jupyter.\n",
    "2.\tPuedes **añadir** todas las celdas que necesites siempre y cuando estén antes del siguiente enunciado.\n",
    "3.\tTodas las celdas **deben estar ejecutadas** y debe visualizarse el resultado de salida.\n",
    "4.\t**No es necesario documentar** las respuestas, simplemente debes hacer lo que se pide en el enunciado.\n",
    "5.\tSi un comando falla, explica la causa del error y cómo lo has solucionado.\n",
    "6.\tDebes entregar tanto el **notebook** (fichero `.ipynb`) como el mismo fichero convertido a **PDF** (es muy probable que si intentas convertirlo en el propio contenedor te falle por no tener instalado `pandoc`, si es así descargalo en formato `.md` o `html` y conviértelo en tu máquina física)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0846a60-c083-4e50-af7d-85d27a788537",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**NOMBRE**:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de87b69-d6ee-43de-83ce-5921d1bd405d",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Uso de HDFS (5.5 puntos de RA1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3c77da-2112-4a53-8a49-9a3c4f97ef95",
   "metadata": {},
   "source": [
    "### Gestión básica y estructura (1.5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391df71c-d395-49fb-84ec-1af121ad76a7",
   "metadata": {},
   "source": [
    "**Preparación del entorno**\n",
    "\n",
    "- Crea un archivo local en tu máquina llamado `datos_alumno.txt`.\n",
    "- El contenido del archivo debe ser tu nombre completo y tu DNI, repetido en 10 líneas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aee2f34-03dc-489c-8ab7-d1f72b936610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A"
     ]
    }
   ],
   "source": [
    "!cat examen/datos_alumno.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995f545-472e-4f73-a0a4-33b787cb9bc2",
   "metadata": {},
   "source": [
    "**Creación de directorios en HDFS**\n",
    "\n",
    "- Crea la siguiente estructura de directorios dentro de HDFS:\n",
    "    - `/examen/{tus_iniciales}/entradas`\n",
    "    - `/examen/{tus_iniciales}/salidas`\n",
    "    - `/examen/{tus_iniciales}/logs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617a3cdd-8a7d-49fe-aa24-380e74d1877e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 08:55 /examen\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-03 11:40 /processed\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-03 11:08 /server-logs\n",
      "drwxrwx---   - root supergroup          0 2025-12-03 11:04 /tmp\n",
      "drwxrwxrwt   - root root                0 2025-12-03 11:39 /yarn\n",
      "Found 1 items\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 08:55 /examen/ing\n",
      "Found 3 items\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 08:55 /examen/ing/entradas\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 08:55 /examen/ing/logs\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 08:55 /examen/ing/salidas\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mkdir /examen/\n",
    "!hdfs dfs -mkdir /examen/ing/\n",
    "!hdfs dfs -mkdir /examen/ing/entradas\n",
    "!hdfs dfs -mkdir /examen/ing/salidas\n",
    "!hdfs dfs -mkdir /examen/ing/logs\n",
    "!hdfs dfs -ls /\n",
    "!hdfs dfs -ls /examen\n",
    "!hdfs dfs -ls /examen/ing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e3f78-7ca6-4e30-a026-bf51ee8cec43",
   "metadata": {},
   "source": [
    "**Ingesta de datos**\n",
    "\n",
    "- Sube el archivo local `datos_alumno.txt` al directorio HDFS `/examen/{tus_iniciales}/entradas`\n",
    "- Verifica que el archivo se ha subido correctamente listando el contenido del directorio\n",
    "- Verifica que el archivo se ha subido correctamente listando el contenido del archivo `datos_alumno.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6fa936-626d-4a2d-b81e-f8741c50368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 root supergroup        289 2025-12-04 08:56 /examen/ing/entradas/datos_alumno.txt\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -put examen/datos_alumno.txt /examen/ing/entradas\n",
    "!hdfs dfs -ls /examen/ing/entradas\n",
    "!hdfs dfs -cat /examen/ing/entradas/datos_alumno.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e37ba3-f436-4b23-879b-42afe764555a",
   "metadata": {},
   "source": [
    "### Manipulación y exploración (1.5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bced13-a4e8-4443-8f7c-c27aa0d3cbb5",
   "metadata": {},
   "source": [
    "**Duplicación y renombrado**\n",
    "\n",
    "- Realiza una copia del archivo que acabas de subir (`datos_alumno.txt`) dentro de HDFS y colócala en la carpeta `/examen/{tus_iniciales}/salidas`.\n",
    "- Renombra esta copia en HDFS para que se llame `backup_datos.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0604a361-d2e4-4a7c-a0f4-003d95823389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 root supergroup        289 2025-12-04 08:57 /examen/ing/salidas/backup_datos.txt\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cp /examen/ing/entradas/datos_alumno.txt /examen/ing/salidas/backup_datos.txt\n",
    "!hdfs dfs -ls /examen/ing/salidas\n",
    "!hdfs dfs -cat /examen/ing/salidas/backup_datos.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a438034-0de2-4f59-8edb-2e5703c99a24",
   "metadata": {},
   "source": [
    "**Inspección de contenido**\n",
    "\n",
    "- Muestra por consola las últimas 3 líneas del archivo `backup_datos.txt` que reside en HDFS\n",
    "- Muestra el tamaño total (en formato legible para los humanos) del directorio `/examen/{tus_iniciales}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9c98db7-62a7-4b58-926c-4e4f2c65aa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "Iker Nieto Garrido 12345678A\n",
      "578  1.7 K  /examen/ing\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /examen/ing/salidas/backup_datos.txt | tail -n 3\n",
    "!echo \"\"\n",
    "!hdfs dfs -du -h -s /examen/ing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f77d34-2620-443e-861b-4fefce665335",
   "metadata": {},
   "source": [
    "**Movimiento de datos**\n",
    "\n",
    "- Mueve el archivo original `/examen/{tus_iniciales}/entradas/datos_alumno.txt` a la carpeta `/examen/{tus_iniciales}/logs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64a2f89d-2cf5-4fcd-be21-66279dd53db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 root supergroup        289 2025-12-04 08:56 /examen/ing/logs/datos_alumno.txt\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mv /examen/ing/entradas/datos_alumno.txt /examen/ing/logs\n",
    "!hdfs dfs -ls /examen/ing/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf2383-ecf5-4e10-a6b1-79b59db2afaf",
   "metadata": {},
   "source": [
    "### Administración avanzada (2.5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76470ab0-8733-44b5-ba6b-5e508a16a763",
   "metadata": {},
   "source": [
    "**Factor de replicación**\n",
    "\n",
    "- Cambia el factor de replicación del archivo `/examen/{tus_iniciales}/salidas/backup_datos.txt` a **1**.\n",
    "- Comprueba que el cambio se ha efectuado correctamente utilizando el comando `fsck` o `ls` con los parámetros adecuados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e2df60-c142-43fb-85f3-28fca588edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to namenode via http://namenode:9870/fsck?ugi=root&path=%2Fexamen%2Fing%2Fsalidas%2Fbackup_datos.txt\n",
      "FSCK started by root (auth:SIMPLE) from /172.19.0.3 for path /examen/ing/salidas/backup_datos.txt at Thu Dec 04 10:17:04 GMT 2025\n",
      "\n",
      "\n",
      "Status: HEALTHY\n",
      " Number of data-nodes:\t4\n",
      " Number of racks:\t\t1\n",
      " Total dirs:\t\t\t0\n",
      " Total symlinks:\t\t0\n",
      "\n",
      "Replicated Blocks:\n",
      " Total size:\t289 B\n",
      " Total files:\t1\n",
      " Total blocks (validated):\t1 (avg. block size 289 B)\n",
      " Minimally replicated blocks:\t1 (100.0 %)\n",
      " Over-replicated blocks:\t0 (0.0 %)\n",
      " Under-replicated blocks:\t0 (0.0 %)\n",
      " Mis-replicated blocks:\t\t0 (0.0 %)\n",
      " Default replication factor:\t3\n",
      " Average block replication:\t3.0\n",
      " Missing blocks:\t\t0\n",
      " Corrupt blocks:\t\t0\n",
      " Missing replicas:\t\t0 (0.0 %)\n",
      " Blocks queued for replication:\t0\n",
      "\n",
      "Erasure Coded Block Groups:\n",
      " Total size:\t0 B\n",
      " Total files:\t0\n",
      " Total block groups (validated):\t0\n",
      " Minimally erasure-coded block groups:\t0\n",
      " Over-erasure-coded block groups:\t0\n",
      " Under-erasure-coded block groups:\t0\n",
      " Unsatisfactory placement block groups:\t0\n",
      " Average block group size:\t0.0\n",
      " Missing block groups:\t\t0\n",
      " Corrupt block groups:\t\t0\n",
      " Missing internal blocks:\t0\n",
      " Blocks queued for replication:\t0\n",
      "FSCK ended at Thu Dec 04 10:17:04 GMT 2025 in 1 milliseconds\n",
      "\n",
      "\n",
      "The filesystem under path '/examen/ing/salidas/backup_datos.txt' is HEALTHY\n"
     ]
    }
   ],
   "source": [
    "!hdfs fsck /examen/ing/salidas/backup_datos.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51845d15-7916-48fb-aed5-dfdc34fa33ab",
   "metadata": {},
   "source": [
    "**Permisos**\n",
    "\n",
    "- Cambia los permisos del directorio `/examen/{tus_iniciales}/logs` para que solo el propietario tenga permisos de lectura, escritura y ejecución. El resto de los usuarios no debe tener acceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19d40e0a-cb1c-4f81-9343-1c966e8ae87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 09:07 /examen/ing/entradas\n",
      "drwx------   - root supergroup          0 2025-12-04 09:07 /examen/ing/logs\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 08:57 /examen/ing/salidas\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -chmod 700 /examen/ing/logs\n",
    "!hdfs dfs -ls /examen/ing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86afb0-0e57-497e-a10d-74049dc9b7ff",
   "metadata": {},
   "source": [
    "**Gestión de cuotas**\n",
    "\n",
    "- Asigna una cuota de espacio al directorio `/examen/{tus_iniciales}/entradas` limitada a 1 MB.\n",
    "- Intenta subir un archivo (o varios) que superen en total 1 MB a ese directorio para demostrar que la cuota funciona.\n",
    "- Elimina la cuota de espacio asignada al directorio `/examen/{tus_iniciales}/entradas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47f29762-dd65-4b3e-8b4b-f0584d23a839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000+0 records in\n",
      "2000000+0 records out\n",
      "1024000000 bytes (1.0 GB, 977 MiB) copied, 2.61824 s, 391 MB/s\n",
      "put: The DiskSpace quota of /examen/ing/entradas is exceeded: quota = 1048576 B = 1 MB but diskspace consumed = 402653184 B = 384 MB\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfsadmin -setSpaceQuota 1M /examen/ing/entradas\n",
    "!dd if=/dev/zero of=big.dat count=2MB\n",
    "!hdfs dfs -put big.dat /examen/ing/entradas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea69529-2528-49d7-a5f5-269182dc3cb4",
   "metadata": {},
   "source": [
    "**Snapshots y recuperación**\n",
    "\n",
    "- Habilita la funcionalidad de snapshots en el directorio `/examen/{tus_iniciales}/salidas`.\n",
    "- Crea un snapshot del directorio `/examen/{tus_iniciales}/salidas` llamado `snap_seguridad_v1`.\n",
    "- Simula un error humano borrando el archivo `/examen/{tus_iniciales}/salidas/backup_datos.txt`.\n",
    "- Recupera el archivo borrado restaurándolo desde el snapshot creado anteriormente.\n",
    "- Comprueba que el archivo vuelve a aparecer en su ubicación original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f3d6a-107a-45df-b244-1b237e4192f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowing snapshot on /examen/ing/salidas succeeded\n",
      "Created snapshot /examen/ing/salidas/.snapshot/snap_seguridad_v1\n",
      "Found 1 items\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 10:21 /examen/ing/salidas/.snapshot/snap_seguridad_v1\n",
      "rm: `/examen/ing/salidas/backup_datos.txt': No such file or directory\n",
      "Found 4 items\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 10:14 /examen/ing/salidas/genero\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 09:58 /examen/ing/salidas/genero_mas_popular\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 09:58 /examen/ing/salidas/genero_mas_popular_tmp\n",
      "drwxr-xr-x   - root supergroup          0 2025-12-04 10:15 /examen/ing/salidas/rentabilidad\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfsadmin -allowSnapshot /examen/ing/salidas\n",
    "!hdfs dfs -createSnapshot /examen/ing/salidas snap_seguridad_v1\n",
    "!hdfs dfs -ls /examen/ing/salidas/.snapshot\n",
    "!hdfs dfs -rm /examen/ing/salidas/backup_datos.txt\n",
    "# No recuerdo como restaurar un snapshot\n",
    "!hdfs dfs -ls /examen/ing/salidas\n",
    "# Las salidas extra son de los ejercicios mapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5d6c4-c629-4b0e-b9c9-c7267ad7e5c0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a4eb7-106c-47ab-9390-95dc94bdafab",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Computación distribuida con MapReduce (10 puntos de RA2)\n",
    "\n",
    "Esta parte del examen la vamos a hacer con el *dataset* que puedes encontrar en [https://www.kaggle.com/datasets/ashpalsingh1525/imdb-movies-dataset](https://www.kaggle.com/datasets/ashpalsingh1525/imdb-movies-dataset) y que contiene datos sobre más de 10000 películas de IMDB. El fichero del *dataset* te lo habrá facilitado el profesor junto con el examen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "02a2f134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 root supergroup    6622610 2025-12-04 09:41 /examen/ing/entradas/clean_file_bueno.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfsadmin -clrSpaceQuota /examen/ing/entradas\n",
    "!hdfs dfs -put examen/clean_file_bueno.csv /examen/ing/entradas\n",
    "!hdfs dfs -ls /examen/ing/entradas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d8f28-bb46-4813-885a-15ebc1e7f332",
   "metadata": {},
   "source": [
    "## Número de películas por género"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306debcd-a30c-4b71-9456-c1adec9aa9fd",
   "metadata": {},
   "source": [
    "**Número de películas de cada género**\n",
    "\n",
    "Queremos saber **cuántas películas hay en cada uno de los géneros**. Ten en cuenta que muchas películas pertenecen a más de un género. Consejo: antes de empezar observa y familiarízate con la estructura de los datos del fichero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea935c2a-42b3-4cea-9ad2-4b3aa1a512fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examen/genero/mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile examen/genero/mapper.py\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "first = True\n",
    "for line in sys.stdin:\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "    categories = line.split(\",\")[3]\n",
    "    for category in categories.split(\";\"):\n",
    "        if len(category.strip()) == 0:\n",
    "            continue\n",
    "        print(f\"({category}\\t1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "979a13e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examen/genero/reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile examen/genero/reducer.py\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "\n",
    "current_category = None\n",
    "current_count = 0\n",
    "for line in sys.stdin:\n",
    "    category, _ = line.strip().split(\"\\t\")\n",
    "    if category == current_category:\n",
    "        current_count += 1\n",
    "    else:\n",
    "        if current_category:\n",
    "            print(f\"{current_category}\\t{current_count})\")\n",
    "        current_category = category\n",
    "        current_count = 1\n",
    "if current_category:\n",
    "    print(f\"{current_category}\\t{current_count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "84f1b4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Action\t2752)\n",
      "(Adventure\t1890)\n",
      "(Animation\t1468)\n",
      "(Comedy\t2943)\n",
      "(Crime\t1272)\n",
      "(Documentary\t217)\n",
      "(Drama\t3812)\n",
      "(Family\t1407)\n",
      "(Fantasy\t1382)\n",
      "(History\t422)\n",
      "(Horror\t1554)\n",
      "(Music\t277)\n",
      "(Mystery\t862)\n",
      "(Romance\t1576)\n",
      "(Science Fiction\t1261)\n",
      "(TV Movie\t212)\n",
      "(Thriller\t2605)\n",
      "(War\t282)\n",
      "(Western\t131)\n"
     ]
    }
   ],
   "source": [
    "!cat examen/clean_file_bueno.csv | python3 examen/genero/mapper.py | sort | python3 examen/genero/reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f769ee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /examen/ing/salidas/genero/_SUCCESS\n",
      "Deleted /examen/ing/salidas/genero/part-00000\n",
      "2025-12-04 09:53:13,930 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [examen/genero/mapper.py, examen/genero/reducer.py, /tmp/hadoop-unjar7816060380070300737/] [] /tmp/streamjob6739491587663008266.jar tmpDir=null\n",
      "2025-12-04 09:53:14,353 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.4:8032\n",
      "2025-12-04 09:53:14,423 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.4:8032\n",
      "2025-12-04 09:53:14,591 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764838331228_0007\n",
      "2025-12-04 09:53:14,853 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2025-12-04 09:53:14,931 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2025-12-04 09:53:15,025 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764838331228_0007\n",
      "2025-12-04 09:53:15,026 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2025-12-04 09:53:15,134 INFO conf.Configuration: resource-types.xml not found\n",
      "2025-12-04 09:53:15,135 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2025-12-04 09:53:15,176 INFO impl.YarnClientImpl: Submitted application application_1764838331228_0007\n",
      "2025-12-04 09:53:15,195 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764838331228_0007/\n",
      "2025-12-04 09:53:15,195 INFO mapreduce.Job: Running job: job_1764838331228_0007\n",
      "2025-12-04 09:53:19,257 INFO mapreduce.Job: Job job_1764838331228_0007 running in uber mode : false\n",
      "2025-12-04 09:53:19,257 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2025-12-04 09:53:22,293 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2025-12-04 09:53:26,316 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2025-12-04 09:53:26,326 INFO mapreduce.Job: Job job_1764838331228_0007 completed successfully\n",
      "2025-12-04 09:53:26,367 INFO mapreduce.Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=368512\n",
      "\t\tFILE: Number of bytes written=1679509\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=6626932\n",
      "\t\tHDFS: Number of bytes written=282\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=3179\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1272\n",
      "\t\tTotal time spent by all map tasks (ms)=3179\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1272\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3179\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1272\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=3255296\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1302528\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10179\n",
      "\t\tMap output records=26323\n",
      "\t\tMap output bytes=315860\n",
      "\t\tMap output materialized bytes=368518\n",
      "\t\tInput split bytes=226\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=19\n",
      "\t\tReduce shuffle bytes=368518\n",
      "\t\tReduce input records=26323\n",
      "\t\tReduce output records=19\n",
      "\t\tSpilled Records=52646\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=174\n",
      "\t\tCPU time spent (ms)=1800\n",
      "\t\tPhysical memory (bytes) snapshot=999022592\n",
      "\t\tVirtual memory (bytes) snapshot=7847297024\n",
      "\t\tTotal committed heap usage (bytes)=1331691520\n",
      "\t\tPeak Map Physical memory (bytes)=323674112\n",
      "\t\tPeak Map Virtual memory (bytes)=2617184256\n",
      "\t\tPeak Reduce Physical memory (bytes)=357896192\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2618499072\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=6626706\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=282\n",
      "2025-12-04 09:53:26,367 INFO streaming.StreamJob: Output directory: /examen/ing/salidas/genero\n",
      "(Action\t2752)\n",
      "(Adventure\t1890)\n",
      "(Animation\t1468)\n",
      "(Comedy\t2942)\n",
      "(Crime\t1272)\n",
      "(Documentary\t217)\n",
      "(Drama\t3812)\n",
      "(Family\t1407)\n",
      "(Fantasy\t1382)\n",
      "(History\t422)\n",
      "(Horror\t1554)\n",
      "(Music\t277)\n",
      "(Mystery\t862)\n",
      "(Romance\t1575)\n",
      "(Science Fiction\t1261)\n",
      "(TV Movie\t212)\n",
      "(Thriller\t2605)\n",
      "(War\t282)\n",
      "(Western\t131)\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm /examen/ing/salidas/genero/*\n",
    "!hdfs dfs -rmdir /examen/ing/salidas/genero\n",
    "!hadoop jar \\\n",
    "/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \\\n",
    "-file examen/genero/mapper.py \\\n",
    "-mapper examen/genero/mapper.py \\\n",
    "-file examen/genero/reducer.py \\\n",
    "-reducer examen/genero/reducer.py \\\n",
    "-input /examen/ing/entradas/clean_file_bueno.csv \\\n",
    "-output /examen/ing/salidas/genero\n",
    "!hdfs dfs -cat /examen/ing/salidas/genero/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33312c3-2947-4992-b100-40ba775d18b8",
   "metadata": {},
   "source": [
    "**Género más popular**\n",
    "\n",
    "Utilizando MapReduce, averigua cuál es el género más popular. Debes utilizar un segundo proceso MapReduce para procesar la salida del anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "46639124-a8c7-40c2-8945-e889bbffd51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examen/genero_mas_popular/mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile examen/genero_mas_popular/mapper.py\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "\n",
    "biggest_count = 0\n",
    "biggest_genre = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "    genre, count = line.strip().split(\"\\t\")\n",
    "    count = int(count.split(\")\")[0])\n",
    "    if biggest_count < count:\n",
    "        biggest_genre = genre.split(\"(\")[1]\n",
    "        biggest_count = count\n",
    "print(f\"({biggest_count}\\t{biggest_genre})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c0ff9ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examen/genero_mas_popular/reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile examen/genero_mas_popular/reducer.py\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "\n",
    "biggest_count = 0\n",
    "biggest_genre = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "    count, genre = line.strip().split(\"\\t\")\n",
    "    count = int(count.split(\"(\")[1])\n",
    "    if biggest_count < count:\n",
    "        biggest_genre = genre.split(\")\")[0]\n",
    "        biggest_count = count\n",
    "print(f\"({biggest_count}\\t{biggest_genre})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2c0fedda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3812\tDrama)\n"
     ]
    }
   ],
   "source": [
    "!cat examen/clean_file_bueno.csv | python3 examen/genero/mapper.py | sort | python3 examen/genero/reducer.py | python3 examen/genero_mas_popular/mapper.py | sort | python3 examen/genero_mas_popular/reducer.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "56bd3e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/examen/ing/salidas/genero_mas_popular/*': No such file or directory\n",
      "Deleted /examen/ing/salidas/genero_mas_popular_tmp/_SUCCESS\n",
      "Deleted /examen/ing/salidas/genero_mas_popular_tmp/part-00000\n",
      "2025-12-04 09:58:18,870 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [examen/genero/mapper.py, examen/genero/reducer.py, /tmp/hadoop-unjar596608990877596713/] [] /tmp/streamjob5632819618262006077.jar tmpDir=null\n",
      "2025-12-04 09:58:19,241 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.4:8032\n",
      "2025-12-04 09:58:19,304 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.4:8032\n",
      "2025-12-04 09:58:19,454 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764838331228_0010\n",
      "2025-12-04 09:58:19,693 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2025-12-04 09:58:19,763 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2025-12-04 09:58:19,847 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764838331228_0010\n",
      "2025-12-04 09:58:19,847 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2025-12-04 09:58:19,961 INFO conf.Configuration: resource-types.xml not found\n",
      "2025-12-04 09:58:19,962 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2025-12-04 09:58:20,001 INFO impl.YarnClientImpl: Submitted application application_1764838331228_0010\n",
      "2025-12-04 09:58:20,020 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764838331228_0010/\n",
      "2025-12-04 09:58:20,021 INFO mapreduce.Job: Running job: job_1764838331228_0010\n",
      "2025-12-04 09:58:24,072 INFO mapreduce.Job: Job job_1764838331228_0010 running in uber mode : false\n",
      "2025-12-04 09:58:24,072 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2025-12-04 09:58:27,113 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2025-12-04 09:58:31,135 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2025-12-04 09:58:31,144 INFO mapreduce.Job: Job job_1764838331228_0010 completed successfully\n",
      "2025-12-04 09:58:31,189 INFO mapreduce.Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=368512\n",
      "\t\tFILE: Number of bytes written=1679557\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=6626932\n",
      "\t\tHDFS: Number of bytes written=282\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=3069\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1424\n",
      "\t\tTotal time spent by all map tasks (ms)=3069\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1424\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3069\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1424\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=3142656\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1458176\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10179\n",
      "\t\tMap output records=26323\n",
      "\t\tMap output bytes=315860\n",
      "\t\tMap output materialized bytes=368518\n",
      "\t\tInput split bytes=226\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=19\n",
      "\t\tReduce shuffle bytes=368518\n",
      "\t\tReduce input records=26323\n",
      "\t\tReduce output records=19\n",
      "\t\tSpilled Records=52646\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=178\n",
      "\t\tCPU time spent (ms)=1750\n",
      "\t\tPhysical memory (bytes) snapshot=1005395968\n",
      "\t\tVirtual memory (bytes) snapshot=7847489536\n",
      "\t\tTotal committed heap usage (bytes)=1322254336\n",
      "\t\tPeak Map Physical memory (bytes)=325226496\n",
      "\t\tPeak Map Virtual memory (bytes)=2615603200\n",
      "\t\tPeak Reduce Physical memory (bytes)=360120320\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2620186624\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=6626706\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=282\n",
      "2025-12-04 09:58:31,189 INFO streaming.StreamJob: Output directory: /examen/ing/salidas/genero_mas_popular_tmp\n",
      "2025-12-04 09:58:31,987 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [examen/genero_mas_popular/mapper.py, examen/genero_mas_popular/reducer.py, /tmp/hadoop-unjar7766384367512419657/] [] /tmp/streamjob3732379814715694656.jar tmpDir=null\n",
      "2025-12-04 09:58:32,355 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.4:8032\n",
      "2025-12-04 09:58:32,425 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.4:8032\n",
      "2025-12-04 09:58:32,574 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764838331228_0011\n",
      "2025-12-04 09:58:32,818 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2025-12-04 09:58:32,891 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2025-12-04 09:58:32,978 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764838331228_0011\n",
      "2025-12-04 09:58:32,978 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2025-12-04 09:58:33,080 INFO conf.Configuration: resource-types.xml not found\n",
      "2025-12-04 09:58:33,080 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2025-12-04 09:58:33,115 INFO impl.YarnClientImpl: Submitted application application_1764838331228_0011\n",
      "2025-12-04 09:58:33,131 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764838331228_0011/\n",
      "2025-12-04 09:58:33,131 INFO mapreduce.Job: Running job: job_1764838331228_0011\n",
      "2025-12-04 09:58:40,206 INFO mapreduce.Job: Job job_1764838331228_0011 running in uber mode : false\n",
      "2025-12-04 09:58:40,206 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2025-12-04 09:58:44,257 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2025-12-04 09:58:48,287 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2025-12-04 09:58:48,305 INFO mapreduce.Job: Job job_1764838331228_0011 completed successfully\n",
      "2025-12-04 09:58:48,363 INFO mapreduce.Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=39\n",
      "\t\tFILE: Number of bytes written=942707\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=673\n",
      "\t\tHDFS: Number of bytes written=13\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=2826\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1399\n",
      "\t\tTotal time spent by all map tasks (ms)=2826\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1399\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=2826\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1399\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=2893824\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1432576\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=19\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=29\n",
      "\t\tMap output materialized bytes=45\n",
      "\t\tInput split bytes=250\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=45\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=190\n",
      "\t\tCPU time spent (ms)=1040\n",
      "\t\tPhysical memory (bytes) snapshot=992288768\n",
      "\t\tVirtual memory (bytes) snapshot=7844888576\n",
      "\t\tTotal committed heap usage (bytes)=1348993024\n",
      "\t\tPeak Map Physical memory (bytes)=322904064\n",
      "\t\tPeak Map Virtual memory (bytes)=2614276096\n",
      "\t\tPeak Reduce Physical memory (bytes)=349016064\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2617229312\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=423\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=13\n",
      "2025-12-04 09:58:48,363 INFO streaming.StreamJob: Output directory: /examen/ing/salidas/genero_mas_popular\n",
      "(3812\tDrama)\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm /examen/ing/salidas/genero_mas_popular/*\n",
    "!hdfs dfs -rmdir /examen/ing/salidas/genero_mas_popular\n",
    "!hdfs dfs -rm /examen/ing/salidas/genero_mas_popular_tmp/*\n",
    "!hdfs dfs -rmdir /examen/ing/salidas/genero_mas_popular_tmp\n",
    "!hadoop jar \\\n",
    "/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \\\n",
    "-file examen/genero/mapper.py \\\n",
    "-mapper examen/genero/mapper.py \\\n",
    "-file examen/genero/reducer.py \\\n",
    "-reducer examen/genero/reducer.py \\\n",
    "-input /examen/ing/entradas/clean_file_bueno.csv \\\n",
    "-output /examen/ing/salidas/genero_mas_popular_tmp\n",
    "!hadoop jar \\\n",
    "/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \\\n",
    "-file examen/genero_mas_popular/mapper.py \\\n",
    "-mapper examen/genero_mas_popular/mapper.py \\\n",
    "-file examen/genero_mas_popular/reducer.py \\\n",
    "-reducer examen/genero_mas_popular/reducer.py \\\n",
    "-input /examen/ing/salidas/genero_mas_popular_tmp/part-00000 \\\n",
    "-output /examen/ing/salidas/genero_mas_popular\n",
    "!hdfs dfs -cat /examen/ing/salidas/genero_mas_popular/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95790afb-2bbd-485f-80d4-83037bb9084b",
   "metadata": {},
   "source": [
    "**País con películas más rentables**\n",
    "\n",
    "Queremos saber qué país tiene una filmografía más rentable (ten en cuenta que *budget*=presupuesto, *revenue*=ingresos), así que tienes que obtener un listado de países y beneficios promedio por película ((total ingresos - total presupuestos) / número películas de ese país)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7ba39163-386d-4cd7-8688-34dc078f3eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examen/rentabilidad/mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile examen/rentabilidad/mapper.py\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "\n",
    "current_country = None\n",
    "current_count = 0\n",
    "current_profit = 0\n",
    "first = True\n",
    "for line in sys.stdin:\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "    values = line.strip().split(\",\")\n",
    "    country = values[-1]\n",
    "    revenue = float(values[-2])\n",
    "    budget = float(values[-3])\n",
    "    if country == current_country:\n",
    "        current_count += 1\n",
    "        current_profit += revenue - budget\n",
    "    else:\n",
    "        if current_country:\n",
    "            print(f\"({current_country}\\t{current_profit / current_count})\")\n",
    "        current_country = country\n",
    "        current_count = 1\n",
    "        current_profit = revenue - budget\n",
    "if current_country:\n",
    "    print(f\"({current_country}\\t{current_profit / current_count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8b9dbc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examen/rentabilidad/reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile examen/rentabilidad/reducer.py\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "\n",
    "current_country = None\n",
    "current_profit = 0\n",
    "for line in sys.stdin:\n",
    "    country, profit = line.strip().split(\"\\t\")\n",
    "    country = country.split(\"(\")[1]\n",
    "    profit = profit.split(\")\")[0]\n",
    "    profit = float(profit)\n",
    "    if country == current_country:\n",
    "        current_profit += profit\n",
    "    else:\n",
    "        if current_country:\n",
    "            print(f\"({country}\\t{int(current_profit)})\")\n",
    "        current_country = country\n",
    "        profit = profit\n",
    "if current_country:\n",
    "    print(f\"({country}\\t{int(current_profit)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5818269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AT\t14032700075)\n",
      "(AU\t14071265610)\n",
      "(BE\t333339451775)\n",
      "(BO\t335273217307)\n",
      "(BR\t335273217307)\n",
      "(BY\t345284673523)\n",
      "(CA\t345284673523)\n",
      "(CH\t358062809377)\n",
      "(CL\t359056667624)\n",
      "(CN\t361462863913)\n",
      "(CO\t381814986573)\n",
      "(CZ\t388203924933)\n",
      "(DE\t388209433072)\n",
      "(DK\t412886123711)\n",
      "(DO\t417437679549)\n",
      "(ES\t417437679549)\n",
      "(FI\t456820718694)\n",
      "(FR\t457189578432)\n",
      "(GB\t507765574753)\n",
      "(GR\t545826875299)\n",
      "(GT\t546427679118)\n",
      "(HK\t547178928148)\n",
      "(HU\t577877598526)\n",
      "(ID\t578320440941)\n",
      "(IE\t580686468864)\n",
      "(IL\t582608489603)\n",
      "(IN\t582608489603)\n",
      "(IR\t589722726569)\n",
      "(IS\t590050017117)\n",
      "(IT\t590643634947)\n",
      "(JP\t624322959216)\n",
      "(KH\t779686770190)\n",
      "(KR\t779686770190)\n",
      "(LV\t867811109628)\n",
      "(MU\t867811109628)\n",
      "(MX\t867811109628)\n",
      "(MY\t907578746068)\n",
      "(NL\t907583251341)\n",
      "(NO\t912512148907)\n",
      "(PE\t915071462045)\n",
      "(PH\t916930244403)\n",
      "(PL\t926438826987)\n",
      "(PR\t933831426833)\n",
      "(PT\t934417614850)\n",
      "(PY\t934417614850)\n",
      "(RU\t934417614850)\n",
      "(SE\t942250125695)\n",
      "(SG\t944366556188)\n",
      "(SK\t945240597046)\n",
      "(SU\t945241267045)\n",
      "(TH\t946007617528)\n",
      "(TR\t954841087080)\n",
      "(TW\t959533877162)\n",
      "(UA\t963798686922)\n",
      "(US\t964212387599)\n",
      "(UY\t1371476868523)\n",
      "(VN\t1371575008970)\n",
      "(XC\t1371990326684)\n",
      "(ZA\t1371990326684)\n",
      "(ZA\t1372191135684)\n"
     ]
    }
   ],
   "source": [
    "!cat examen/clean_file_bueno.csv | python3 examen/rentabilidad/mapper.py | sort | python3 examen/rentabilidad/reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13002505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/examen/ing/salidas/rentabilidad/*': No such file or directory\n",
      "rmdir: `/examen/ing/salidas/rentabilidad': No such file or directory\n",
      "2025-12-04 10:15:44,441 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [examen/rentabilidad/mapper.py, examen/rentabilidad/reducer.py, /tmp/hadoop-unjar5256461430713055006/] [] /tmp/streamjob8198722047655061184.jar tmpDir=null\n",
      "2025-12-04 10:15:44,824 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.4:8032\n",
      "2025-12-04 10:15:44,884 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.4:8032\n",
      "2025-12-04 10:15:45,034 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764838331228_0014\n",
      "2025-12-04 10:15:45,260 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2025-12-04 10:15:45,330 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2025-12-04 10:15:45,413 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764838331228_0014\n",
      "2025-12-04 10:15:45,414 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2025-12-04 10:15:45,505 INFO conf.Configuration: resource-types.xml not found\n",
      "2025-12-04 10:15:45,505 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2025-12-04 10:15:45,543 INFO impl.YarnClientImpl: Submitted application application_1764838331228_0014\n",
      "2025-12-04 10:15:45,561 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764838331228_0014/\n",
      "2025-12-04 10:15:45,561 INFO mapreduce.Job: Running job: job_1764838331228_0014\n",
      "2025-12-04 10:15:49,612 INFO mapreduce.Job: Job job_1764838331228_0014 running in uber mode : false\n",
      "2025-12-04 10:15:49,612 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2025-12-04 10:15:53,657 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2025-12-04 10:15:56,679 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2025-12-04 10:15:57,699 INFO mapreduce.Job: Job job_1764838331228_0014 completed successfully\n",
      "2025-12-04 10:15:57,759 INFO mapreduce.Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=135259\n",
      "\t\tFILE: Number of bytes written=1213057\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=6626932\n",
      "\t\tHDFS: Number of bytes written=1083\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=2962\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1361\n",
      "\t\tTotal time spent by all map tasks (ms)=2962\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1361\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=2962\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1361\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=3033088\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1393664\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10179\n",
      "\t\tMap output records=6848\n",
      "\t\tMap output bytes=121557\n",
      "\t\tMap output materialized bytes=135265\n",
      "\t\tInput split bytes=226\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=60\n",
      "\t\tReduce shuffle bytes=135265\n",
      "\t\tReduce input records=6848\n",
      "\t\tReduce output records=60\n",
      "\t\tSpilled Records=13696\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=179\n",
      "\t\tCPU time spent (ms)=1550\n",
      "\t\tPhysical memory (bytes) snapshot=1003520000\n",
      "\t\tVirtual memory (bytes) snapshot=7842693120\n",
      "\t\tTotal committed heap usage (bytes)=1320681472\n",
      "\t\tPeak Map Physical memory (bytes)=324329472\n",
      "\t\tPeak Map Virtual memory (bytes)=2613858304\n",
      "\t\tPeak Reduce Physical memory (bytes)=365613056\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2616729600\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=6626706\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1083\n",
      "2025-12-04 10:15:57,759 INFO streaming.StreamJob: Output directory: /examen/ing/salidas/rentabilidad\n",
      "(AT\t13549196752)\n",
      "(AU\t13587762287)\n",
      "(BE\t332235349594)\n",
      "(BO\t334169115126)\n",
      "(BR\t334169115126)\n",
      "(BY\t343473000367)\n",
      "(CA\t343473000367)\n",
      "(CH\t356241663912)\n",
      "(CL\t356682078543)\n",
      "(CN\t359088274832)\n",
      "(CO\t378974221265)\n",
      "(CZ\t384633691495)\n",
      "(DE\t384639199634)\n",
      "(DK\t408835270613)\n",
      "(DO\t413144093609)\n",
      "(ES\t413144093609)\n",
      "(FI\t452085881524)\n",
      "(FR\t452456013656)\n",
      "(GB\t503001819931)\n",
      "(GR\t541056339291)\n",
      "(GT\t541665737470)\n",
      "(HK\t542055417943)\n",
      "(HU\t572107176788)\n",
      "(ID\t572812159409)\n",
      "(IE\t574768776858)\n",
      "(IL\t576469814270)\n",
      "(IN\t576469814270)\n",
      "(IR\t583571674682)\n",
      "(IS\t583572914744)\n",
      "(IT\t584166532574)\n",
      "(JP\t617004433895)\n",
      "(KH\t772286053047)\n",
      "(KR\t772286053047)\n",
      "(LV\t860054239569)\n",
      "(MU\t860054239569)\n",
      "(MX\t860054239569)\n",
      "(MY\t899566950772)\n",
      "(NL\t899589548782)\n",
      "(NO\t904452166104)\n",
      "(PE\t907020342337)\n",
      "(PH\t908472347948)\n",
      "(PL\t917563143806)\n",
      "(PR\t924648808666)\n",
      "(PT\t925234996682)\n",
      "(PY\t925234996682)\n",
      "(RU\t925234996682)\n",
      "(SE\t933118686555)\n",
      "(SG\t935028727557)\n",
      "(SK\t935902768415)\n",
      "(SU\t935903438414)\n",
      "(TH\t936700242096)\n",
      "(TR\t945471133895)\n",
      "(TW\t949814337158)\n",
      "(UA\t953740002111)\n",
      "(US\t954153702788)\n",
      "(UY\t1361249365090)\n",
      "(VN\t1361182695089)\n",
      "(XC\t1361598012803)\n",
      "(ZA\t1361598012803)\n",
      "(ZA\t1361966333125)\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm /examen/ing/salidas/rentabilidad/*\n",
    "!hdfs dfs -rmdir /examen/ing/salidas/rentabilidad\n",
    "!hadoop jar \\\n",
    "/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \\\n",
    "-file examen/rentabilidad/mapper.py \\\n",
    "-mapper examen/rentabilidad/mapper.py \\\n",
    "-file examen/rentabilidad/reducer.py \\\n",
    "-reducer examen/rentabilidad/reducer.py \\\n",
    "-input /examen/ing/entradas/clean_file_bueno.csv \\\n",
    "-output /examen/ing/salidas/rentabilidad\n",
    "!hdfs dfs -cat /examen/ing/salidas/rentabilidad/part-00000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
