{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432cba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/15 08:43:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# print(f\"SPARK_HOME='{os.environ['SPARK_HOME']}'\")\n",
    "# print(f\"JAVA_HOME='{os.environ['JAVA_HOME']}'\")\n",
    "# print(f\"PYTHONPATH='{os.environ.get('PYTHONPATH', '')}'\")\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = ( SparkSession.builder\n",
    "            .appName(\"pruebas\")\n",
    "            .master(\"spark://spark-master:7077\")\n",
    "            .getOrCreate()\n",
    "        )\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a8c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"Ana\", 15),\n",
    "    (\"Carlos\", 22),\n",
    "    (\"Luis\", 10),\n",
    "    (\"Marta\", 35)\n",
    "]\n",
    "\n",
    "columns = [\"nombre\", \"edad\"]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1972f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|nombre|edad|\n",
      "+------+----+\n",
      "|   Ana|  15|\n",
      "|Carlos|  22|\n",
      "|  Luis|  10|\n",
      "| Marta|  35|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "        .format(\"tipo_archivo\")\n",
    "        .option(\"clave\", \"valor\")\n",
    "        .schema(mi_schema)\n",
    "        .load(\"ruta/al/archivo\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
